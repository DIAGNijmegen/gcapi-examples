{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grand Challenge API Client: interact with grand-challenge.org via python\n",
    "## Chapter: Algorithms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pipeline.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GC-API provides a handy functionality to interract with grand-challenge.org via python.\n",
    "\n",
    "Its purpose and broader functionality is discussed in details in [this](https://grand-challenge.org/blogs/grand-challenge-api-client/) blogpost. In order to use gc-api you will also need to obtain a personal API token. The blog above describe what it is and where to find it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will focus on grand-challenge Algorithms and in details go over following steps:\n",
    "\n",
    "1. [Uploading input to Algorithms on grand-challenge.org for inference.](#section_1)\n",
    "2. [Downloading inference results from an Algorithm on grand-challenge.org.](#section_2)\n",
    "3. [Uploading multiple item input to an Algorithm on grand-challenge.org.](#section_3)\n",
    "4. [Downloading the results of an algorithm that produces multiple item output.](#section_4)\n",
    "\n",
    "Remember that you need to request a permission prior to using an algorithm. You do not need to request a permission if you are using your own algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install gcapi --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nessesary libraries\n",
    "import gcapi\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the API token to authentificate to grand-challenge platform via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#authorise with your personal token\n",
    "my_personal_GC_API_token = ''\n",
    "client = gcapi.Client(token=my_personal_GC_API_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1. Uploading input to Algorithms on grand-challenge.org for inference.](#section_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use [Pulmonary Lobe Segmentation](https://grand-challenge.org/algorithms/pulmonary-lobe-segmentation/) by Weiyi Xie. This algorithm performs automatic segmentation of pulmonary lobes of a given chest CT scan. The algorithm uses a contextual two-stage U-Net architecture. We will use example chest CT scans from [coronacases.org](coronacases.org). They are anonimized.\n",
    "We will now upload the CT scans of Covid-19 patients to Pulmonary Lobe Segmentation algorithm on grand-challenge using GC-API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the algorithm, providing a slug\n",
    "algorithm_1 = client.algorithms.detail(slug=\"pulmonary-lobe-segmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore, which input the algorithm expects\n",
    "algorithm_1[\"inputs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the inputs to the algorithm one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grand-challenge creats a job instance for each set of inputs. To create a job instance use a command:\n",
    "\n",
    "    job = client.run_external_job(algorithm=\"slug-of-the-algorithm\", inputs={ \"interface\": [ file ] }),\n",
    "    \n",
    "where argument \"algorithm\" expects a str with a slug of the algorithm you want to use and argument \"inputs\" expects a dictionary where keys are expected interfaces and the file is str path/url to a particular input file. \n",
    "\n",
    "Be aware that with this version (0.5.0) the input file path/url needs be placed into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the path to the files\n",
    "files = [\"io/case01.mha\", \"io/case02.mha\"]\n",
    "#timeout\n",
    "jobs = []\n",
    "\n",
    "# submit a job for each file in your file list\n",
    "for file in files:\n",
    "    \n",
    "    job = client.run_external_job(\n",
    "        algorithm=\"pulmonary-lobe-segmentation\",\n",
    "        inputs={\n",
    "            \"generic-medical-image\": [Path(file)]\n",
    "        }\n",
    "    )\n",
    "    jobs.append(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the statuses of the submitted jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [client.algorithm_jobs.detail(job[\"pk\"]) for job in jobs]\n",
    "\n",
    "print([job[\"status\"] for job in jobs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of your jobs have ended up with a status 'Succeeded', you can download the results. You can also use infer the Algorithm on existing Archive on grand-challenge.org (if you have been granted access to it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2. Downloading inference results from an Algorithm on grand-challenge.org.](#section_2)\n",
    "\n",
    "#### Download the results from the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through input files \n",
    "for job, input_fname in tqdm(zip(jobs, files)):\n",
    "    \n",
    "    # loop through job outputs \n",
    "    for output in job[\"outputs\"]:\n",
    "        \n",
    "        # check whether if output exists\n",
    "        if output[\"image\"] is not None:\n",
    "            \n",
    "            # get image details\n",
    "            image_details = client(url=output[\"image\"])\n",
    "            print('image_details',image_details)\n",
    "            for file in image_details[\"files\"]:\n",
    "                print('file',file)\n",
    "                # create the output filename\n",
    "                output_file = Path(input_fname.replace(\".mha\", \"_lobes.mha\"))\n",
    "                if output_file.suffix != \".mha\":\n",
    "                    raise ValueError(\"Output file needs to have .mha extension\")\n",
    "                output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "                with output_file.open(\"wb\") as fp:\n",
    "                    # get the impage from url and write it \n",
    "                    response = client(url = file[\"file\"],follow_redirects=True).content\n",
    "                    fp.write(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3. Uploading multiple item input to an Algorithm on grand-challenge.org.](#section_3)\n",
    "\n",
    "\n",
    "In this section we will take a look, on how to upload multiple item input to an Algorithm on grand-challenge.org. Asw an example we will use Alessa Herrings Algorithm - [Deep Learning-Based Lung Registration](https://grand-challenge.org/algorithms/deep-learning-based-ct-lung-registration/).\n",
    "\n",
    "This algorithm requires the following inputs:\n",
    "1. fixed image (CT)\n",
    "2. fixed mask (lungs segmentation)\n",
    "3. moving image (CT)\n",
    "4. moving mask (lungs segmentation)\n",
    "\n",
    "We will use the scans from the previous section as well as the Algorithm output (lung lobes segmentation) in this section. Therefore, we will have to binarize the lobe masks and create lung masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarize the masks obtained from previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide paths of the lobe segmentations\n",
    "lobes = [\n",
    "    \"io/case01_lobes.mha\",\n",
    "    \"io/case02_lobes.mha\",\n",
    "]\n",
    "#loop through the files\n",
    "for lobe_file in lobes:\n",
    "    #read image with sitk\n",
    "    lobe = sitk.ReadImage(lobe_file)\n",
    "    origin, spacing, direction = lobe.GetOrigin(), lobe.GetSpacing(), lobe.GetDirection()\n",
    "    lobe = sitk.GetArrayFromImage(lobe)\n",
    "    # binarize\n",
    "    lobe[lobe > 1] = 1\n",
    "    lungs = lobe.astype(np.uint8)\n",
    "    lungs = sitk.GetImageFromArray(lungs)\n",
    "    lungs.SetOrigin(origin)\n",
    "    lungs.SetSpacing(spacing)\n",
    "    lungs.SetDirection(direction)\n",
    "    #write the modified image back into file\n",
    "    sitk.WriteImage(lungs, lobe_file.replace(\"_lobes\", \"_lungs\"), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the algorithm\n",
    "algorithm_2 = client.algorithms.detail(slug=\"deep-learning-based-ct-lung-registration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the algorithm object\n",
    "You can inspect the algorithm object to understand what kind of inputs it requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_2[\"inputs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the inputs to the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a job\n",
    "registration_job = client.run_external_job(\n",
    "    algorithm=\"deep-learning-based-ct-lung-registration\",\n",
    "    inputs={\n",
    "        \"fixed-image\": [Path(\"io/case01.mha\")],\n",
    "        \"moving-image\": [Path(\"io/case02.mha\")],\n",
    "        \"fixed-mask\": [Path(\"io/case01_lungs.mha\")],\n",
    "        \"moving-mask\": [Path(\"io/case02_lungs.mha\")],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the status of the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_job = client.algorithm_jobs.detail(registration_job[\"pk\"])\n",
    "registration_job[\"status\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the results\n",
    "\n",
    "After the status of the job is `Succeeded`, you can procceed to downloading the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the outputs \n",
    "for output in registration_job[\"outputs\"]:\n",
    "    print('output',output)\n",
    "    # get image details\n",
    "    image_details = client(url=output[\"image\"])\n",
    "    output_slug = output[\"interface\"][\"slug\"]\n",
    "    print(\"Downloading\", output_slug)\n",
    "    for file in image_details[\"files\"]:\n",
    "        output_file = Path(f\"{output_slug}.mha\")\n",
    "        output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with output_file.open(\"wb\") as fp:\n",
    "          \n",
    "            fp.write(client(url=file[\"file\"], follow_redirects=True).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both these algorithms wrote `.mha` files as outputs. For algorithms that require different outputs, you can loop through the outputs of a successful job and search under \"interface\", which will tell you what kind of outputs you will have to download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4. Downloading the results of an algorithm that produces multiple item output.](#section_4)\n",
    "\n",
    "In this section we will focus on how to download  results from an algorithm that produces multiple outputs. We will use the algorithm for pulmonary lobes segmentation Covid-19 cases. This algorithm output the segmentation for a particular input as well as a \"screenshot\" of a middle slice for rapid inspection of algorithm performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the algorithm, providing a slug\n",
    "algorithm_4 = client.algorithms.detail(slug=\"pulmonary-lobe-segmentation-for-covid-19-ct-scans\")\n",
    "\n",
    "# explore, which input the algorithm expects\n",
    "algorithm_4[\"inputs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will, firstly infer the algorithm on the existing images, exactly the same way we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcapi import Client\n",
    "c = Client(token=my_personal_GC_API_token)\n",
    "\n",
    "#name of the archive \n",
    "archive_slug = \"coronacases.org\"\n",
    "#save path on your machine\n",
    "output_archive_dir = 'output_scans'\n",
    "outputarchivedir_screenshots = 'output_screenshots'\n",
    "\n",
    "archives = c(url=\"https://grand-challenge.org/api/v1/archives/\")[\"results\"]\n",
    "\n",
    "corona_archive = None\n",
    "for archive in archives:\n",
    "    if archive[\"name\"] == archive_slug:\n",
    "        corona_archive = archive\n",
    "        break\n",
    "if corona_archive is None:\n",
    "    raise Exception(\"archive not found on GC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corona_archive)\n",
    "\n",
    "# get information about images in archive from GC API\n",
    "params = {\n",
    "    'archive': corona_archive['id'],\n",
    "}\n",
    "response = c(url=\"https://grand-challenge.org/api/v1/cases/images/\", params=params)\n",
    "#print(response)\n",
    "urls=[]\n",
    "for r in response['results']:\n",
    "    urls.append(r['api_url'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the archive, providing a slug\n",
    "jobs = []\n",
    "\n",
    "# submit a job for each file in your file list\n",
    "for url in urls[:2]:\n",
    "    print(url)\n",
    "    job = client.run_external_job(\n",
    "        algorithm=\"pulmonary-lobe-segmentation-for-covid-19-ct-scans\",\n",
    "        inputs={\n",
    "            \"ct-image\": url\n",
    "        }\n",
    "    )\n",
    "    jobs.append(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the status of the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = [client.algorithm_jobs.detail(job[\"pk\"]) for job in jobs]\n",
    "\n",
    "print([job[\"status\"] for job in jobs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the job status is 'Succeeded' we can procceed to downloading the results. In this part we will go through scenario where we no longer have the details of the particular job that processed algorithm and inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcapi import Client\n",
    "c = Client(token=my_personal_GC_API_token)\n",
    "\n",
    "\n",
    "# get algorithm providing the slug\n",
    "algorithm = \"pulmonary-lobe-segmentation-for-covid-19-ct-scans\"\n",
    "algorithm_details = c(path=\"algorithms/\", params={\"slug\": algorithm})\n",
    "\n",
    "# extract details   \n",
    "algorithm_details = algorithm_details[\"results\"][0]\n",
    "algorithm_uuid = algorithm_details[\"pk\"]\n",
    "\n",
    "# Define dictionaries for image uuid mappings\n",
    "images_mapping = {}\n",
    "images_mapping_scans = {}\n",
    "\n",
    "# get the desired archive\n",
    "archives = c(url=\"https://grand-challenge.org/api/v1/archives/\")[\"results\"]\n",
    "archive_slug = 'coronacases.org'\n",
    "target_archive = None\n",
    "\n",
    "# loop through archives and select the one with a slug that you are looking for ('coronacases.org')\n",
    "for archive in archives:\n",
    "    if archive[\"name\"] == archive_slug:\n",
    "        target_archive = archive\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have generated a set of outputs to a set of inputs. Now, we need to find out which output corresponds to which input. This can be figured out via unique identifiers of images. Each image in an archive has a unique identifier (uuid). Here we create a **mapping between input image names and uuids**. We collect the uuids to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get uuids in archive\n",
    "done = False\n",
    "iteration = 0\n",
    "image_uuids = []\n",
    "# create a mapping between image uuids and input names\n",
    "while not done:\n",
    "    iteration += 1\n",
    "    if iteration == 1:\n",
    "        # get information about images in archive from GC API\n",
    "        params = {'archive': target_archive['id']}\n",
    "        response = c(url=\"https://grand-challenge.org/api/v1/cases/images/\", params=params)\n",
    "    else:\n",
    "        # get information about images on next page\n",
    "        response = c(url=response[\"next\"])\n",
    "    images = response['results']\n",
    "    for image in images:\n",
    "        # create a mapping for image uuids\n",
    "        uuid = image['pk']\n",
    "        images_mapping[uuid] = image['name'] + \"_\" + uuid\n",
    "        images_mapping_scans[uuid] = image['name'] \n",
    "        image_uuids += [uuid]\n",
    "    if response[\"next\"] is None:\n",
    "        # stop if no next page left\n",
    "        done = True\n",
    "print('image_uuids:',image_uuids)\n",
    "print('--------------------------------------------------------------------------------------------------------')\n",
    "print('images_mapping_scans:',images_mapping_scans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will loop through uuids and collect the algorithm job details corresponding to each unique image identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get algorithm results for the image\n",
    "output_image_files = []\n",
    "screenshot_files = []\n",
    "counter = 0\n",
    "# loop through uuid\n",
    "for image_uuid in image_uuids:\n",
    "    params = {'algorithm_image__algorithm': algorithm_uuid, 'input_image': image_uuid}\n",
    "    # get the jobs details corresponding to a particular uuid and algorithm\n",
    "    results = c.algorithm_jobs.iterate_all(params)\n",
    "    #iterate through the results\n",
    "    for result in results:\n",
    "        counter += 1\n",
    "        print('--------------------------------------------------------------------------------------------------------')\n",
    "        #iterate through the outputs\n",
    "        for output in result['outputs']:\n",
    "            # here we go over different interfaces and write the corresponding output\n",
    "            print('interface:',output[\"interface\"][\"slug\"])\n",
    "            if output[\"interface\"][\"slug\"] == \"pulmonary-lobes\":\n",
    "                image = c(url=output['image'])\n",
    "                for file in image[\"files\"]:\n",
    "                    if file['image_type'] == \"MHD\":\n",
    "                        new_file = file['file']#image['files'][0]['file']\n",
    "                        output_image_files += [new_file]\n",
    "                        dest_path_mha = Path(os.path.join(output_archive_dir, images_mapping_scans[image_uuid]))\n",
    "                        with open(dest_path_mha, 'wb') as f1:\n",
    "                            response_1 = c(url=new_file, follow_redirects=True)\n",
    "                            f1.write(response_1.content)\n",
    "                            print(dest_path_mha)\n",
    "            if output[\"interface\"][\"slug\"] == \"pulmonary-lobes-screenshot\":\n",
    "                image = c(url=output['image'])\n",
    "                for file in image[\"files\"]:\n",
    "                    if file['image_type'] == \"TIFF\":\n",
    "                        new_file = file['file']\n",
    "                        screenshot_files += [new_file]\n",
    "                        dest_path = os.path.join(outputarchivedir_screenshots, images_mapping[image_uuid] + '.tif')\n",
    "                        with open(dest_path, 'wb') as f1:\n",
    "                            response_2 = c(url=new_file, follow_redirects=True)\n",
    "                            f1.write(response_2.content)\n",
    "                            print(dest_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
